{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1MSJyAcptKfCokQ7qFI2GO_k4ORPkRH5n","authorship_tag":"ABX9TyOLItAGE/3o94wy2YNXJYru"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":227,"metadata":{"id":"zQ2ZiHsJT90j","executionInfo":{"status":"ok","timestamp":1720382023854,"user_tz":-330,"elapsed":386,"user":{"displayName":"Karan Prajapati","userId":"04505719894971420600"}}},"outputs":[],"source":["# @title Importing libraries and dataset\n","\n","import numpy as np\n","import pandas as pd\n","\n","dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Machine Learning/AspireNex/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n","\n","X = dataset.iloc[:, 1:-1].values\n","y = dataset.iloc[:, -1].values"]},{"cell_type":"code","source":["# @title cleaning the data\n","from sklearn.impute import SimpleImputer\n","\n","imputer = SimpleImputer(missing_values=' ', strategy=\"constant\", fill_value = '0')\n","imputer.fit(X[:, -1:])\n","X[:, -1:] = imputer.transform(X[:, -1:])\n","\n","X[:, -1] = X[:, -1].astype(float)"],"metadata":{"id":"otXMu6q3mjN9","executionInfo":{"status":"ok","timestamp":1720382024556,"user_tz":-330,"elapsed":7,"user":{"displayName":"Karan Prajapati","userId":"04505719894971420600"}}},"execution_count":228,"outputs":[]},{"cell_type":"code","source":["# @title Encoding the Single Categorical data\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","\n","le = LabelEncoder()\n","label_category = [2, 3, 5, 15]\n","\n","X[:, 0] = le.fit_transform(X[:, 0])\n","\n","le.fit(X[:, 2])\n","for i in label_category:\n","    X[:, i] = le.transform(X[:, i])\n","\n","y = le.transform(y)"],"metadata":{"id":"cI5F3fOuVPYf","executionInfo":{"status":"ok","timestamp":1720382024557,"user_tz":-330,"elapsed":6,"user":{"displayName":"Karan Prajapati","userId":"04505719894971420600"}}},"execution_count":229,"outputs":[]},{"cell_type":"code","source":["# @title Encoding the Multiple Categorical data\n","from sklearn.compose import ColumnTransformer\n","\n","ct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [6, 7, 8, 9, 10, 11, 12, 13, 14, 16])], remainder = 'passthrough')\n","X = np.array(ct.fit_transform(X))"],"metadata":{"id":"GfaPz4JdhOmF","executionInfo":{"status":"ok","timestamp":1720382024558,"user_tz":-330,"elapsed":6,"user":{"displayName":"Karan Prajapati","userId":"04505719894971420600"}}},"execution_count":230,"outputs":[]},{"cell_type":"code","source":["# @title Spliting the data into training set and test set\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"],"metadata":{"id":"g1i_y2nQn-dP","executionInfo":{"status":"ok","timestamp":1720382024558,"user_tz":-330,"elapsed":5,"user":{"displayName":"Karan Prajapati","userId":"04505719894971420600"}}},"execution_count":231,"outputs":[]},{"cell_type":"code","source":["# @title Feature Scaling\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","sc = StandardScaler()\n","\n","X_train[:, -2:] = sc.fit_transform(X_train[:, -2:])\n","X_test[:, -2:] = sc.transform(X_test[:, -2:])"],"metadata":{"id":"DoTn4S_zoOpf","executionInfo":{"status":"ok","timestamp":1720382025089,"user_tz":-330,"elapsed":535,"user":{"displayName":"Karan Prajapati","userId":"04505719894971420600"}}},"execution_count":232,"outputs":[]},{"cell_type":"code","source":["# @title Training the training set\n","\n","# Logistic Regression (0.797)\n","'''\n","from sklearn.linear_model import LogisticRegression\n","classifier = LogisticRegression()\n","classifier.fit(X_train, y_train)\n","'''\n","\n","# Gradient Boosting (0.783)\n","'''\n","from sklearn.ensemble import GradientBoostingClassifier\n","classifier = GradientBoostingClassifier()\n","classifier.fit(X_train, y_train)\n","'''\n","\n","# Random Forest (0.774)\n","'''\n","from sklearn.ensemble import RandomForestClassifier\n","classifier = RandomForestClassifier(random_state=0, n_estimators = 100, criterion = 'entropy')\n","classifier.fit(X_train, y_train)\n","'''\n","\n","# Decision Tree (0.731)\n","'''\n","from sklearn.tree import DecisionTreeClassifier\n","classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n","classifier.fit(X_train, y_train)\n","'''"],"metadata":{"id":"hMHRgaaPpAoC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Predicting the test set results\n","y_pred = classifier.predict(X_test)"],"metadata":{"id":"FsEiEwr4p-_b","executionInfo":{"status":"ok","timestamp":1720382025702,"user_tz":-330,"elapsed":13,"user":{"displayName":"Karan Prajapati","userId":"04505719894971420600"}}},"execution_count":234,"outputs":[]},{"cell_type":"code","source":["# @title Making the Confusion Matrix and Getting the Accuracy of model\n","\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)"],"metadata":{"id":"DPtp2GHprdGj"},"execution_count":null,"outputs":[]}]}